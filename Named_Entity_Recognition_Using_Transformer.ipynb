{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pramod858/Named-Entity-Recognition-Using-Transformers/blob/main/Named_Entity_Recognition_Using_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Named Entity Recognition Using Tranformers"
      ],
      "metadata": {
        "id": "3pLJbzvUeJoX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwDUFKDdR6i_"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "ntIbn-RaRzbs"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets evaluate\n",
        "!pip install -q seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D31_Au7nR_oc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "ZslyJl_QV7rt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "import sklearn### machine learning library\n",
        "import cv2## image processing\n",
        "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
        "import seaborn as sns### visualizations\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import evaluate\n",
        "import time\n",
        "from numpy import random\n",
        "import gensim.downloader as api\n",
        "from PIL import Image\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Dense,Flatten,InputLayer,BatchNormalization,Dropout,Input,LayerNormalization\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from datasets import load_dataset\n",
        "from transformers import (BertTokenizerFast,TFBertTokenizer,BertTokenizer,RobertaTokenizerFast,DataCollatorForTokenClassification,\n",
        "                          DataCollatorWithPadding,TFRobertaForSequenceClassification,TFBertForSequenceClassification,\n",
        "                          TFBertModel,create_optimizer,TFRobertaForTokenClassification,TFAutoModelForTokenClassification,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "8phsQmoYUJWK"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE=16\n",
        "NUM_EPOCHS=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3CEdBN2aX9k"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " CONLL2003 is a widely used dataset for evaluating natural language processing (NLP) systems. It contains annotation on a wide range of NLP tasks, including named entity recognition, sentiment analysis, and parsing. The dataset is drawn from the Wall Street Journal and other newspapers, and it includes about 20,000 document paragraphs that have been manually annotated by human annotators. The data is split into several different sets, including training, validation, and test sets, and it is widely used in research and industry for developing NLP systems.  "
      ],
      "metadata": {
        "id": "9kAi2f9aK1zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "id": "bl5b-DkIm3uW"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z75hTVqhRngx",
        "outputId": "d0c8877a-9f21-484f-bfc7-c4f1224c1a2c"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlD8IEqNhQ9q",
        "outputId": "bb870740-d54b-4fbc-9151-a7cf29acacd9"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "    num_rows: 14041\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Roberta-base is a language modeling framework developed by Google. It uses a denoising autoencoder approach and is pre-trained on a large corpus of text. It is highly effective in a variety of natural language processing tasks, including text classification, named entity recognition, and question answering. In contrast to other models like BERT, Roberta-base only requires input sequencing from the user and is capable of generating coherent text in a few seconds. However, it is worth noting that its model size is significantly larger compared to other models in the domain.  "
      ],
      "metadata": {
        "id": "7VA4JrUuKPLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id=\"roberta-base\"\n",
        "tokenizer=RobertaTokenizerFast.from_pretrained(model_id,add_prefix_space=True)"
      ],
      "metadata": {
        "id": "J2R8WPVx_Rf8"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(dataset[\"train\"][2][\"tokens\"], is_split_into_words=True,)\n",
        "inputs.tokens()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgeoy1gF_Rii",
        "outputId": "a719fd4b-b33d-4a05-96c7-3efd430d00f6"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'ĠBR', 'USS', 'ELS', 'Ġ1996', '-', '08', '-', '22', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M4nCJp4C-nz",
        "outputId": "f1326ef4-2dad-4108-95ab-b3dea05bc890"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '2', 'tokens': ['BRUSSELS', '1996-08-22'], 'pos_tags': [22, 11], 'chunk_tags': [11, 12], 'ner_tags': [5, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.word_ids())\n",
        "print(dataset['train'][2]['ner_tags'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T-2oqzZ_Rkr",
        "outputId": "74ec3023-535c-45e9-f2bd-3de81df38c46"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, 0, 0, 0, 1, 1, 1, 1, 1, None]\n",
            "[5, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            # Start of a new word!\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        elif word_id is None:\n",
        "            # Special token\n",
        "            new_labels.append(-100)\n",
        "        else:\n",
        "            # Same word as previous token\n",
        "            label = labels[word_id]\n",
        "            # If the label is B-XXX we change it to I-XXX\n",
        "            if label % 2 == 1:\n",
        "                label += 1\n",
        "            new_labels.append(label)\n",
        "\n",
        "    return new_labels"
      ],
      "metadata": {
        "id": "h4tRbGntAHIQ"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = dataset[\"train\"][2][\"ner_tags\"]\n",
        "word_ids = inputs.word_ids()\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ],
      "metadata": {
        "id": "1_TuyCIgAHKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094ff6b4-b957-4af1-a6e4-3e6990325c85"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 0]\n",
            "[-100, 5, 6, 6, 0, 0, 0, 0, 0, -100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer_function(dataset):\n",
        "  out=tokenizer(dataset[\"tokens\"],truncation=True,is_split_into_words=True,)\n",
        "  out['labels']=align_labels_with_tokens(dataset[\"ner_tags\"],out.word_ids())\n",
        "  return out"
      ],
      "metadata": {
        "id": "CSwkgKlmAHMr"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset=dataset.map(tokenizer_function,remove_columns=['id','tokens','pos_tags','chunk_tags','ner_tags',])"
      ],
      "metadata": {
        "id": "hZYXRoIuAHR_"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "cUjwdGatAHUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a29dee4e-d6c2-414e-c517-04d8ebaeb093"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset['train'][2])"
      ],
      "metadata": {
        "id": "ok0W52hGAHW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e117e1-f3e3-4fb4-a0fa-382a647b5105"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [0, 6823, 16551, 16416, 8008, 12, 3669, 12, 2036, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 5, 6, 6, 0, 0, 0, 0, 0, -100]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A data collator is a function that takes a list of samples from a dataset and combines them into batches for efficient processing."
      ],
      "metadata": {
        "id": "MP634uTBNKIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForTokenClassification(\n",
        "    tokenizer=tokenizer, return_tensors=\"tf\"\n",
        ")"
      ],
      "metadata": {
        "id": "iWx2T18M_Rms"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_dataset = tokenized_dataset[\"train\"].to_tf_dataset(\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ],
      "metadata": {
        "id": "VQjN-qFD_Ro8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78032782-a8e2-42f2-ab46-13bb8fb1b3a0"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_val_dataset = tokenized_dataset[\"validation\"].to_tf_dataset(\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ],
      "metadata": {
        "id": "yTmUHqDy_RrI"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tf_train_dataset.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "qF1zQGfu_Rtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f5124d-ca7a-4933-d1f5-ce61d69ca652"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(16, 41), dtype=int64, numpy=\n",
            "array([[    0,  1463, 18912,    36, 11270,  4839,   440,   545,  5449,\n",
            "           73,  5607,     9,   291,   830,  8008, 10584,     5,  2526,\n",
            "         6595,  3266,    13, 13684,     5,  3555,   425,     9,  1402,\n",
            "         6231,     8,  8942, 34588,  3243, 34330,  5725,  5382,   479,\n",
            "            2,     1,     1,     1,     1],\n",
            "       [    0, 24566, 11757,  2444,  1723,  8008,    12,  3669,    12,\n",
            "         2890,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0,  6189, 15402, 21115,   262,   155,   112,   155,   262,\n",
            "          361,   158,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0,    20,  3576, 34456,    26,    10, 31701,  1829,   333,\n",
            "         5942,     5,  2398,     8,    26,    15,   302,    51,    56,\n",
            "           70,    57,  1835,   479,     2,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0,   832,  2868,     7,     5,  1756,     7,   124,    39,\n",
            "         2120,     7, 25403,    38, 15124, 16312,    21,  3752,     7,\n",
            "         6726,  2156,  1066,    26,   479,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0,  1489,   692,  7860,   281,  6202, 10100,  5888,   381,\n",
            "         9942,   452,    13, 26921,  8141,    10,   707,    12,  2300,\n",
            "          776,  3737,    14,  1523,   629,  3500,     7, 18751,     8,\n",
            "           97,  5197,  2156,   723, 15131,     7,  3111,     8,   323,\n",
            "           13,   650,   265,   479,     2],\n",
            "       [    0,  7975,  1417,   174,   234,  2915,  2384,    15,   395,\n",
            "           37,    21,    11,   117,  4854,     8,  3604,    37,    74,\n",
            "           28,   124,    11,     5,  3716,  3691,   479,    22,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0,   497,     5,  1151,    42,    16,    45,     5,   403,\n",
            "          479,    22,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0,   231,     4, 25186,   155,   132,   111,   112,   290,\n",
            "          262,   231,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0,   204,     4,    83,   560, 20837,   261,    36, 23686,\n",
            "         4839,   158,     4,  1092,     2,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0,   256,  3196,   347,  4581,  8008,    12,  3669,    12,\n",
            "         2518,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0,   111,    83,  1481,   118, 47098,     9,   316,  5657,\n",
            "            9,  7666,  8842,    11,   121,  5471,  1209,   281,   338,\n",
            "         4103,    11,     5,  4602,   479,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0,  1811,   337,  1071,  2156,    54,  1550,   371,    94,\n",
            "          191,  2156, 13795,     7,    10,   155,    12,   134,   483,\n",
            "           23,  7143,   479,     2,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0,    20,  4019,  3522,  1387,    26,     5,  6178,  8272,\n",
            "           11,     5, 16457,   812,    56,  9702,     5,  6769,  1342,\n",
            "         2485,     9,     5,   411,     7,    10,   400,  8501,     8,\n",
            "           56,  3604,    51,    74,    28, 14313,    30,   830,   883,\n",
            "          479,     2,     1,     1,     1],\n",
            "       [    0,  2618,  2812,  4903,  1910,    36,  2809,  4839,  1451,\n",
            "        16086,  1378,    36,  4637,  4839,   262,    12,   401,    36,\n",
            "          290,    12,   401,  4839,   155,    12,   401,   231,    12,\n",
            "          176,   231,    12,   176,     2,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1],\n",
            "       [    0, 40114,  4377,   975,  2604,  7744,   111,  5178,   525,\n",
            "          717,  2118,  5945, 17164, 25746, 28408,  7536,  2808, 22123,\n",
            "         3732,    83,  5499, 22556,   479,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1]])>, 'attention_mask': <tf.Tensor: shape=(16, 41), dtype=int64, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>, 'labels': <tf.Tensor: shape=(16, 41), dtype=int64, numpy=\n",
            "array([[-100,    7,    8,    0,    3,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100, -100, -100, -100, -100],\n",
            "       [-100,    5,    6,    6,    6,    0,    0,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    3,    4,    4,    0,    0,    0,    0,    0,    0,    0,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    0,    7,    8,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    1,    2,    2,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    1,    2,    2,    2,    0,    1,    2,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0, -100],\n",
            "       [-100,    1,    2,    0,    3,    4,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    1,    2,    2,    2,    0,    5,    0,    0,\n",
            "           0,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    5,    6,    6,    6,    0,    0,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    5,    6,    6,    6,    6,    0,    0,    0,    5,\n",
            "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    3,    4,    4,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    0,    3,    4,    4,    0,    0,    3,    4,    0,    0,\n",
            "           7,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0, -100, -100, -100, -100],\n",
            "       [-100,    1,    2,    2,    2,    0,    5,    0,    0,    1,    2,\n",
            "           0,    5,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       [-100,    3,    4,    4,    4,    4,    0,    5,    6,    6,    6,\n",
            "           6,    0,    0,    0,    0,    0,    5,    6,    6,    6,    6,\n",
            "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100]])>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQiSVkoLaaqF"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Based on TFRobertaForSequenceClassification"
      ],
      "metadata": {
        "id": "s3Rf_9bFLJsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFRobertaForSequenceClassification\" is a specific model architecture in the TensorFlow library that is designed for sequence classification tasks. It is based on the RoBERTa model, which is a variant of the BERT (Bidirectional Encoder Representations from Transformers) model."
      ],
      "metadata": {
        "id": "89cacwYnN6Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=TFRobertaForTokenClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=9,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuzC0evWPis2",
        "outputId": "a5bd1e22-2d0c-4eb0-9a0c-d75afaa62f35"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForTokenClassification: ['roberta.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFRobertaForTokenClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX74Nb8_JSYT",
        "outputId": "5465d42d-aa43-43aa-da77-a5d6e48f6443"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_roberta_for_token_classification_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " roberta (TFRobertaMainLaye  multiple                  124055040 \n",
            " r)                                                              \n",
            "                                                                 \n",
            " dropout_189 (Dropout)       multiple                  0         \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  6921      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124061961 (473.26 MB)\n",
            "Trainable params: 124061961 (473.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "E2xsaKH0ySx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batches_per_epoch = len(tokenized_dataset[\"train\"]) // BATCH_SIZE\n",
        "total_train_steps = int(batches_per_epoch*NUM_EPOCHS)"
      ],
      "metadata": {
        "id": "t4RQ6qxuJz6b"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer, schedule = create_optimizer(init_lr=2e-5,num_warmup_steps=0, num_train_steps=total_train_steps,)"
      ],
      "metadata": {
        "id": "1KU0RzAtJz8o"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer,)\n",
        "    #metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "1h_UIuxFJ1si"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(\n",
        "    tf_train_dataset,\n",
        "    validation_data=tf_val_dataset,\n",
        "    epochs=NUM_EPOCHS,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szeGXC2bLr0M",
        "outputId": "77bc3801-5c0e-40ed-ff62-163168edd910"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "878/878 [==============================] - 279s 237ms/step - loss: 0.1485 - val_loss: 0.0511\n",
            "Epoch 2/2\n",
            "878/878 [==============================] - 191s 217ms/step - loss: 0.0425 - val_loss: 0.0445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "dcwVfKoVJ1xF",
        "outputId": "e746becd-42e5-45f3-e9a2-5bc545b53677"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "obCwC6fGPa04"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "uNsioXENbXFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seqeval is a Python library for sequence labeling evaluation.\n",
        "It provides metrics such as precision, recall, and F1 score for sequence labeling tasks.\n",
        "Seqeval supports various sequence labeling tasks such as named entity recognition, part-of-speech tagging, and semantic role labeling."
      ],
      "metadata": {
        "id": "SHU6g70zO_2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric=evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "id": "DL8AG6ypbYVn"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_label={0:'O', 1:'B-PER',2:'I-PER',3:'B-ORG',4:'I-ORG',5:'B-LOC',6:'I-LOC',7:'B-MISC',8:'I-MISC'}\n",
        "all_predictions = []\n",
        "all_labels = []"
      ],
      "metadata": {
        "id": "xFF39QleqZEL"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in tf_val_dataset:\n",
        "  logits = model.predict(batch)[\"logits\"]\n",
        "  labels = batch[\"labels\"].numpy()\n",
        "  predictions = tf.argmax(logits, axis=-1).numpy()\n",
        "  #print(labels)\n",
        "  #print(predictions)\n",
        "  for prediction, label in zip(predictions, labels):\n",
        "    for predicted_idx, label_idx in zip(prediction, label):\n",
        "      if label_idx == -100:\n",
        "          continue\n",
        "      all_predictions.append(ind_to_label[predicted_idx])\n",
        "      all_labels.append(ind_to_label[label_idx])"
      ],
      "metadata": {
        "id": "2uz3DiXmrVuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70969991-ffed-4dd6-e1ad-0c5f120649c1"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 153ms/step\n",
            "1/1 [==============================] - 0s 159ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 165ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 240ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 185ms/step\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 169ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_predictions[:20])\n",
        "print(all_labels[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t10V40RWrVwp",
        "outputId": "423563f3-00c8-40ab-c8e6-ba9a6572c09c"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=[all_predictions], references=[all_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6VKZGbbrVzO",
        "outputId": "48ad3833-2647-4225-9afb-ecc5e52f24aa"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': {'precision': 0.9631436314363143,\n",
              "  'recall': 0.9673380511703865,\n",
              "  'f1': 0.9652362846279195,\n",
              "  'number': 1837},\n",
              " 'MISC': {'precision': 0.8301698301698301,\n",
              "  'recall': 0.9013015184381779,\n",
              "  'f1': 0.8642745709828392,\n",
              "  'number': 922},\n",
              " 'ORG': {'precision': 0.914327917282127,\n",
              "  'recall': 0.9231916480238628,\n",
              "  'f1': 0.9187384044526901,\n",
              "  'number': 1341},\n",
              " 'PER': {'precision': 0.9705093833780161,\n",
              "  'recall': 0.9826275787187839,\n",
              "  'f1': 0.9765308875101161,\n",
              "  'number': 1842},\n",
              " 'overall_precision': 0.9325638911788953,\n",
              " 'overall_recall': 0.9518680578929654,\n",
              " 'overall_f1': 0.9421170983592904,\n",
              " 'overall_accuracy': 0.9876039397379645}"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jbgoKV070Gr"
      },
      "source": [
        "# Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "5H8Y9MERnfX2"
      },
      "outputs": [],
      "source": [
        "inputs=tokenizer([\"You just got a call from UNESCO for a trip to India\"], padding=True,return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.tokens())\n",
        "print(inputs.word_ids())\n",
        "print(inputs['input_ids'])"
      ],
      "metadata": {
        "id": "hEML0foO8ps0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf408333-fb29-4be9-e73f-1715a3f4d03e"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', 'ĠYou', 'Ġjust', 'Ġgot', 'Ġa', 'Ġcall', 'Ġfrom', 'ĠUNESCO', 'Ġfor', 'Ġa', 'Ġtrip', 'Ġto', 'ĠIndia', '</s>']\n",
            "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, None]\n",
            "tf.Tensor(\n",
            "[[    0   370    95   300    10   486    31 26688    13    10  1805     7\n",
            "    666     2]], shape=(1, 14), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model(**inputs).logits\n",
        "print(logits.shape)\n",
        "print(tf.argmax(logits,axis=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEejdLfqTH8q",
        "outputId": "8b443c41-7047-4e46-f6da-a450e125e9d3"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 14, 9)\n",
            "tf.Tensor([[0 0 0 0 0 0 0 3 0 0 0 0 5 0]], shape=(1, 14), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_label={0:'O', 1:'B-PER',2:'I-PER',3:'B-ORG',4:'I-ORG',5:'B-LOC',6:'I-LOC',7:'B-MISC',8:'I-MISC'}\n",
        "out_str=\"\"\n",
        "current_index=0"
      ],
      "metadata": {
        "id": "vD8KCGS-ZD8-"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,len(inputs.tokens())-1):\n",
        "  if tf.argmax(logits,axis=-1)[0][i]!=0:\n",
        "    out_str+=\" \"+str(inputs.tokens()[i])+\"--->\"+str(ind_to_label[tf.argmax(logits,axis=-1).numpy()[0][i]])\n",
        "  else:\n",
        "    out_str+=\" \"+str(inputs.tokens()[i])"
      ],
      "metadata": {
        "id": "5nyowCqaZvqo"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(out_str.replace(\"Ġ\",\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7NKkBVEZvtI",
        "outputId": "6f3ee191-8d56-4422-d6f1-807f4f768787"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " You just got a call from UNESCO--->B-ORG for a trip to India--->B-LOC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jy8laOu6Zvvf"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lLMuwOulZvxo"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1UNqHlTTJ2L"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G_IvJ_PwTJ4d"
      },
      "execution_count": 176,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}